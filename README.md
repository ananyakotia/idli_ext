# India Data Lab Initiative (IDLI)

## Overview
The India Data Lab Initiative (IDLI) harmonizes India’s flagship household and firm surveys so researchers can work with consistent, analysis-ready microdata. By standardizing layouts, reconciling evolving classification systems, and validating outputs against official benchmarks, the lab lowers the fixed cost of using datasets such as the National Sample Surveys (NSS) and the Annual Survey of Industries (ASI).{**ASI Datasets coming soon**}

This repository provides a standardized, reproducible Stata-based pipeline for processing and cleaning publicly available NSS labour, NSS consumption, NSS enterprise and ASI datasets. The goal of this project is to make high-quality, fully cleaned, analysis-ready datasets easily accessible to:

- Researchers  
- Academicians  
- Policy analysts    
- Students and data users  

The scripts convert publicly available raw data into consistent, harmonized, clean `.dta` outputs, ensuring that users can directly begin analysis without spending time on data wrangling.

## Key Features
1. Fully automated data cleaning and data processing pipeline  
2. Generates standardized clean `.dta` files  
3. Master do-files allow one-click end-to-end execution
4. Modular script structure (extract → clean → process → validate)  
5. Compatibility across systems — users only update their paths, not the code  
6. Ensures consistency, reproducibility, and minimal manual intervention

## Repository layout
NSS_Labour/                      # Main folder

├── 00_master_nss_lab.do         # Master script (runs the entire pipeline)

├── 01_variable_clean.do         # Central variable cleaning logic
├── 01_clean_append_lab.do       # Appends cleaned household + person files

│
│   Household-level cleaning scripts (HC)
├── 01_1_1983_clean_hc.do
├── 01_1_1987_clean_hc.do
├── 01_1_1993_clean_hc.do
├── 01_1_1999_clean_hc.do
├── 01_1_2003_clean_hc.do
├── 01_1_2004_clean_hc.do
├── 01_1_2005_clean_hc.do
├── 01_1_2007_clean_hc.do
├── 01_1_2009_clean_hc.do
├── 01_1_2011_clean_hc.do

│
│   Person-level cleaning scripts (PC)
├── 01_2_1983_clean_pc.do
├── 01_2_1987_clean_pc.do
├── 01_2_1993_clean_pc.do
├── 01_2_1999_clean_pc.do
├── 01_2_2003_clean_pc.do
├── 01_2_2004_clean_pc.do
├── 01_2_2005_clean_pc.do
├── 01_2_2007_clean_pc.do
├── 01_2_2009_clean_pc.do
├── 01_2_2011_clean_pc.do

│
│   Harmonization scripts
├── 02_nss_consistent_districts.do      # District code harmonization
├── 03_consistent_industry_codes.do     # Industry code harmonization
├── 04_consistent_occupation_codes.do   # Occupation code harmonization

│
└── README.md/                      # (Auto-generated by the master script; not committed)

Master do-files run the entire workflow.  

## How to Use the Code
## Download Raw Data
Raw NSS and ASI datasets (CSV and DTA) are publicly available on the IDLI website. (https://www.idli.dev/)

Download them and store them anywhere (**preferably `Documents` folder**) on your system.
Run the master do-file in Stata

Open Stata and run the master script:

do `00_master_nss_lab.do`

This will:
1. Check/install required packages (if enabled in preamble)
2. Run year-specific household and person cleaning scripts
3. Apply variable harmonization and code mappings
4. Validate outputs and export .dta and .csv files into the output folder

## Check outputs
After the master run completes, go to your output folder (value of $NSS_OUT) and verify files like:

nss_labour_1983_clean.dta 
nss_labour_1987_clean.dta

... etc.

## How to run only part of the pipeline
If you only want to run one round’s person or household cleaning (without running everything), run that specific file:

do `01_1_2007_clean_hc.do`   // household for 2007
do `01_2_2007_clean_pc.do`   // person for 2007

Important:*Only run individual scripts for inspection or validation. Do not modify them.*
Individual scripts may be executed for validation, **but must not be altered**.
- `code/nss/` – Harmonization pipelines for NSS consumption, labor, and enterprise surveys along with shared resources such as district concordances.【C:code/nss/nss_cons/00_master_nss_lab.do†L21-L43】【C:code/nss/district_concordance/nss_lab_ent_dist_merge.do†L5-L45】
- `documentation/` – Supporting materials referenced by the scripts (for example, district concordance workbooks consumed by `nss_lab_ent_dist_merge.do`).【C:code/nss/district_concordance/nss_lab_ent_dist_merge.do†L5-L45】

The entire code base for the project is maintained on GitHub. The following is the folder structure we followed.  

GitHub --> idli_ext --> code --> nss --> nss_lab 


## Harmonization workflows
### NSS surveys
1. **Environment setup** – Run `code/nss/00_preamble.do` to configure system paths, toggle package installation, and register shared directories for NSS/ASI processing.【C:code/ss/00_preamble.do†L1-L144】 Update the `global root` candidates or add your own block if your folder structure differs.
2. **Employment & labor** – Use `code/nss/nss_lab/00_master_nss_lab.do` to process person- and household-level files, derive consistent district/industry/occupation codes, and assemble analysis files and figures.【Ccode/nss/nss_lab/00_master_nss_lab.do†L21-L43】 Downstream scripts in the same folder build shared concordances (`02_nss_consistent_districts.do`, `03_consistent_industry_codes.do`, etc.)

## Data & documentation assets
- District concordance spreadsheets in `documentation/district_concordance/` are imported directly by the Stata code to reconcile NSS labor and enterprise district codes before merging or validation.【C:code/nss/district_concordance/nss_lab_ent_dist_merge.do†L5-L45】
- Additional methodological notes, cleaning logs, and institutional documents live under `documentation/` and can be referenced as needed when adapting the workflows.

## Getting started
1. **Prerequisites** – Stata 17 or later (MP/SE) with access to the proprietary NSS microdata. Some scripts optionally install user-written packages listed in `00_preamble.do`.
2. **Clone the repository** and place it inside the shared directory referenced by your `global root` (e.g., Dropbox or OneDrive) so the relative paths defined in `00_preamble.do` resolve correctly.【F:code/nss/00_preamble.do†L56-L116】
3. **Configure globals** – Modify `code/nss/00_preamble.do` if your environment differs, then run it from Stata to set `$idl`, `$idl_git`, `$code`, and other macros.
4. **Run the desired master script** – For example, `do code/nss/nss_cons/00_master_nss_lab.do` will call all round-specific cleaners and append routines for the consumption surveys.【F:code/nss/nss_cons/00_master_nss_lab.do†L21-L43】 Monitor the log files (where provided) to verify each block completes.

All required Stata packages — including `gtools`, `reghdfe`, `grstyle`, `palettes`, `distinct`, `ftools`, `mipolate`, `nicelabels`, and others — are automatically checked and installed in the script.
Users may install additional packages locally, **but project scripts should remain unchanged.**

## Best practices & rules 
1. Do not modify the cleaning scripts — edits will break consistency across years and across users.
2. Only change the small USER CONFIG block in 00_master_nss_lab.do that sets paths.
3. Keep raw data outside the repo (e.g., in ~/data/NSS_raw/) and keep outputs in ~/data/NSS_working/.
4. Add outputs/, raw data folders, and .dta files to .gitignore.

If you must change a script for research, make a personal copy and document the changes — but do not commit those changes to the main pipeline.

## Troubleshooting
1. **Missing Packages**
If any required package is missing, install it using:
*ssc install <package-name>*
eg.`ssc install gtools`, `ssc install reghdfe`, `ssc install nicelabels`

2. **Path Errors**
Make sure your system path uses correct formatting:
Windows:
*"C:/Users/username/Documents/..."*

*Note*
Correct:   C:/Users/Me/NSS_raw/
Incorrect: C:\Users\Me\NSS_raw\

Mac:
*"/Users/username/Documents/..."*

Linux:
*"/home/username/..."*

3. **Large File Warning**
For large NSS/ASI files, Stata may require:
*set excelxlsxlargefile on*
(This is already included in the script.)

4. **Outputs not generated**
Check that:
`$NSS_RAW` contains correct folders/files

The raw filenames match expected NSS names
You have write permission in `$NSS_OUT`


## Best Practices
Always use the master do-file for full processing.
Use individual scripts (e.g. `code\nss\nss_lab\01_variable_clean.do`) only for reviewing logic.
Never change script structure, variable definitions, or processing rules.
Store raw and processed data in clearly separated directories.

*This project is maintained by the IDLI research and data engineering team.*

## License
This project uses publicly available NSS and ASI datasets.
Processed datasets and scripts follow IDLI licensing and documentation standards.

## Team
- **Ananya Kotia** – Founder and Director  •  [www.ananyakotia.com](https://www.ananyakotia.com)
- **Bharat Singhal** – Research Associate
- **Naila Fatima** – Research Associate (2023–25)
- **Bommi Reddy Meghana** – Research Manager
- **Ayush Chaudhary** – Research Associate

## Contributing
1. Fork the repository and create a feature branch.
2. Run the relevant master script(s) and validation routines to ensure harmonized outputs remain consistent.
3. Submit a pull request summarizing the methodological change, affected rounds, and validation evidence.

Users may:
Submit issues
Suggest enhancements
Contribute documentation

However, core scripts must not be altered under any circumstances to maintain pipeline integrity.

Private raw data are **not** stored in this repository; only code and documentation needed to reproduce the harmonized releases are included.